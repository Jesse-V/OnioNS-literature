
\chapter{SOLUTION}

\section{Overview}

I propose a new DNS system for Tor hidden services, which I am calling EsgalDNS. \emph{Esgal} is a Sindarin Elvish noun from the works of J.R.R Tolkien, meaning ``veil'' or ``cover that hides''.\cite{SindarinDict} EsgalDNS is a distributed DNS system embedded within the Tor network on top of the existing Tor hidden service infrastructure. EsgalDNS shares some design principles with Namecoin and other DNS systems, and its usage is similar to the traditional Clearnet DNS system. At a high level, the system is powered at any given time by a randomly-chosen subset of Tor nodes, whose primary responsibilities are to receive new DNS records from hidden service operators, propagate the records to all parties, and save the records in a main long-term data structure. Other Tor nodes may mirror this data structure, distributing the load and responsibilities to many Tor nodes. The system supports a variety of command and control operations including Query,s Create, Modify, Move, Renew, and Delete. 

\section{Components}

\subsection{Cryptographic Primitives}

Our system makes use of cryptographic hash algorithms, digital signatures, proof-of-work, and a pseudorandom number generator. As the cryptographic data within our system must persist for many years to come, we select well-established algorithms that we predict will remain strong against cryptographic analysis in the immediate future.

\begin{itemize}
	\item Hash function - We choose SHA-384 for most applications for its greater resistance to preimage, collision, and pseudo-collision attacks over SHA-256, which is itself significantly stronger than Tor's default hidden service hash algorithm, SHA-1. Like SHA-512, SHA-384 requires 80 rounds but its output is truncated to 48 bytes rather than the full 64, which saves space.
	\item Digital signatures - Our default method is EMSA-PSS, (EMSA4) a probabilistic signature scheme defined by PKCS1 v2.1 and republished in 2003's RFC 3447, using a Tor node's 1024-bit RSA key with the SHA-384 digest to form the signature appendix. For signatures inside our proof-of-work scheme, we rely on $EMSA-PKCS1-v1_5$, (EMSA3) defined by 1998's RFC 2315. In contrast to EMSA-PSS, its deterministic nature prevents hidden service operators from bypassing the proof-of-work and brute-forcing the signature to validate the record.
	\item Proof-of-work - We select scrypt, a password-based key derivation function which is notable for its large memory and CPU requirements during its operation. The scrypt function provides significantly greater resistance to custom hardware attacks and massively parallel computation primarily due to its memory requirements. This limits attackers to the same software implementation and asymptotic cost as legitimate users.\cite{percival2009stronger} We choose scrypt because of these advantages over other key derivation functions such as SHA-256 or PBKDF2.
	\item Pseudorandom number generation - In applications that require pseudorandom numbers from a known seed, we use the Mersenne Twister generator. In all instances the Mersenne Twister is initialized from the output of a hash algorithm, negating the generator's weakness of producing substandard random output from certain types of initial seeds.
\end{itemize}

We use the JSON format to encode records and databases of records. JSON is significantly more compact than XML, but retains readability. Its support of basic primitive types is highly applicable to our needs. Additionally, we consider the JSON format safer than byte-level encoding.

\subsection{Quorum}

As a distributed system, EsgalDNS may have many participants; any machine with sufficient storage and bandwidth capacity --- including those outside the Tor network --- may perform a full synchronization with the EsgalDNS network and obtain a full mirror of all DNS information. Inside the Tor network, these participants are divided into three main categorizes: \emph{quorum} nodes, quorum node \emph{candidates}, and \emph{mirrors}. \emph{Mirrors} are Tor nodes that have performed a full synchronization and hold a complete copy of all DNS data structures. However, they are either not qualified or have opted out of being a quorum node \emph{candidate}. The requirements to become a candidate are described in the next section. Of those that qualify, the \emph{quorum} is chosen as a random subset from the \emph{candidate} list. The \emph{quorum} perform the main duties of the system, namely broadcasting and recording DNS records from hidden service operators. 

Any party at any time may derive the list of \emph{candidate} nodes and the \emph{quorum} from them by the following procedure:

\begin{enumerate}
	\item Obtain a remote or local archived copy of the consensus document, $ cd $, published 00:00 GMT that morning.
	\item Extract the digital signature and verify $ cd $ against $ PK_{authorities} $.
	\item Construct a numerical list, $ ql $ of qualified Tor nodes (defined below) from $ cd $.
	\item Initialize the Mersenne Twister PRNG with SHA-384($ cd $).
	\item Use the seeded PRNG to randomly scramble $ ql $.
	\item Let the first $ M $ nodes, numbered $ 1 .. M $, define the \emph{quorum}.
\end{enumerate}

The consensus document is an authenticated source of information and entropy that can be safely distributed publicly, so all parties --- in particular Tor nodes and clients --- agree on the members of the \emph{quorum}. As the \emph{quorum} is determined by the consensus document at the beginning of the day, \emph{quorum} nodes have an effective lifetime of 24 hours before they are replaced by a new \emph{quorum}.

When a \emph{candidate} node becomes a member of the \emph{quorum}, it constructs a one-hop bidirectional Tor circuit to all other quorum nodes. These circuits are used for synchronization and must remain alive for the duration of that \emph{quorum}. Overall this creates $ n * (n - 1) / 2 $ new TCP/IP links among \emph{quorum} members.

\subsubsection{Qualifications}

It is essential that \emph{quorum} nodes have an up-to-date and complete copy of all DNS data and be ready to accept new information. Of equal importance, all \emph{quorum} members must have sufficient CPU and bandwidth capabilities to handle the influx of new records and the work involved with propagating these records to other Tor nodes. Fortunately, Tor's infrastructure already provides capabilities to easily find the second criteria: Tor nodes receive the \emph{fast}, \emph{stable}, \emph{running},  and \emph{valid} flags if they have demonstrated their ability to handle large amounts of traffic, have maintained a history of long uptime, are currently online, and have a correct configuration, respectively. As of February 2015, out of the ~7000 nodes participating in the Tor network, ~5400 of these node have these flags. These machines meet the second criteria for qualification as a \emph{quorum candidate}.

To meet the first requirement, Tor nodes must demonstrate their readiness to accept new records. The na\"{i}ve solution to this problem would be have Tor nodes and clients simply ask the node if it was ready, and if so, for the necessary information that demonstrates it. However, this solution quickly runs into the problem of scaling; Tor has ~7000 nodes and ~2,250,000 daily users\cite{TorMetrics}: it is infeasible for any single node to handle queries from all of them. Therefore a better solution is to publish information to the authority nodes that all parties can see in the consensus document. To do this, a Tor node who has completed a full synchronization of the system performs the following:

\begin{enumerate}
	\item Select a \emph{page}-chain according to the rules specified below.
	\item Generate a local \emph{NameCache} (described below), $ nc $ from the \emph{page}-chain.
	\item Let $ s $ be SHA-384($ nc $).
	\item Encode $ s $ to Base64 and truncate to 8 bytes.
	\item Wrap the result in parentheses and append the result to the Contact field in the descriptor sent to the authority nodes.
\end{enumerate}

For this last step, while ideally this information could be placed in a special field set aside for this purpose, to ease integration with existing Tor infrastructure and third-party websites that parse the consensus document (such as Globe or Atlas) we use the Contact field, a user-defined optional entry that Tor relay operators typically use to list methods of contact such as email addresses and PGP keys. EsgalDNS would not be the first system to embed special information in the Contact field; onion-tip.com identifies Bitcoin addresses in the field and then sends portions of any donations to that address, presumably to the Tor relay operator.

The result is appended to the end of the Contact field, and must be updated at least every 24 hours. To become a candidate for membership in the quorum, a node must be a fast and stable node (flags determined and assigned by authority nodes) and must publish this truncated hash that is in the majority of hashes published by other Tor nodes. This can be easily be determined by all parties holding a recent or archived copy of the consensus document. The rules of the network will cause these hashes to be the same across all up-to-date parties, even if there are disagreements among them as to which page-chain to follow. This approach does not thwart malicious collusion, but our system tolerates a low percentage of that, so we don't consider that a significant problem.

%todo: recycling of recods on other chains

\subsection{Page}

A \emph{page} is long-term JSON-encoded textual database held by quorum nodes. It contains five fields, \emph{prevHash}, \emph{recordList}, \emph{consensusDocHash}, \emph{nodeFingerprint}, and \emph{pageSig}. 

\begin{description}
	\item[prevHash] \hfill \\
		The SHA-384 hash of \emph{prevHash}, \emph{recordList}, \emph{consensusDocHash}, and \emph{nodeKey} of a previous page.
	\item[recordList] \hfill \\
		An array of records, sorted alphabetically or in any other globally deterministic manner.
	\item[consensusDocHash] \hfill \\
		The SHA-384 of the morning's consensus document.
	\item[nodeFingerprint] \hfill \\
		The Tor fingerprint of the quorum node, found by generating a hash of the node's public key. This fingerprint is widely used in Tor infrastructure and in third-party tools as a unique identifier for individual Tor nodes.
	\item[pageSig] \hfill \\
		The digital signature of the preceding fields.
\end{description}

Each quorum node holds its page, the pages of the other quorum nodes on that day, and a single archive of the consensus document. 

To generate its page, it first picks a page from the past quorums by the following method:

%according to the following criteria

\begin{enumerate}
	\item Of all chains of pages in the database, ignore any invalid pages and any pages that form chains using those invalid pages. A page may be invalid if it contains records that do not follow specifications, its \emph{consensusDocHash} field does not match the hash of the consensus document on that day, or if \emph{pageSig} does not verify. Invalid pages may suggest that the quorum node was not fully synchronized, that it acted maliciously, or that there was data corruption.
	\item From these valid chains, find the chain that contains the most back-links (not counting today's pages) and choose the most recent page.
	\item If there are multiple chains that satisfy the second condition, choose from among them the page that contains the largest amount of records.
	\item If the third condition cannot be resolved, choose from among them the page that is held by the smallest $ i $ in the $ M $ quorum nodes.
\end{enumerate}

It then takes the SHA-384 of \emph{prevHash}, \emph{recordList}, and \emph{consensusDocHash} of that page, forming \emph{prevHash}. Secondly, it generates \emph{consensusDocHash} by hashing the morning's consensus document. Finally, it hashes the page and generates a digital signature of that hash, storing the result in \emph{pageSig}.

%\begin{figure}[htbp]
%	\centering
%	\begin{tikzpicture}[node distance=2cm, main node/.style={circle, draw, font=\sffamily\Large\bfseries}]
%
%			\node[main node, fill=Bittersweet!50] (1) {10};
%			\node[main node, fill=Apricot!50] (2) [below of=1] {9};
%				\node[main node, fill=BurntOrange!50] (3) [right of=2] {1};
%			\node[main node, fill=ForestGreen!50] (4) [below of=2] {5};
%				\node[main node, fill=LimeGreen!50] (5) [right of=4] {4};
%				\node[main node, fill=OliveGreen!50] (6) [right of=5] {2};
%				\node[main node, fill=Goldenrod!50] (7) [right of=6] {1};
%			\node[main node, fill=Blue!50] (8) [below of=4] {9};
%				\node[main node, fill=Cyan!50] (9) [right of=8] {1};
%			
%			\tikzstyle{EdgeStyle}=[->, thick, blue]
%			
%			% main chain
%			\Edge[](8)(4)
%			\Edge[](4)(2)
%			\Edge[](2)(1)
%			
%			% day 4 branches
%			\Edge[](9)(5)
%			
%			% day 3 branches
%			\Edge[](5)(2)
%			\Edge[](6)(2)
%			\Edge[](7)(3)
%			
%			% day 2 branches
%			\Edge[](3)(1)
%			
%		\end{tikzpicture}
%	\caption{Sample page-chain on day 4. Quorum size is $ M = 10 $, the numbers represent quorum participants with the same page. Despite malicious collusion and misbehaving nodes on day 3, most of day 4's quorum choose the correct chain with $ 10 + 9 + 1 + 5 + 4 + 2 = 31 $ total participants.}
%	\label{fig:figure5}
%\end{figure}

\subsection{Snapshot}

Similar to a page, a \emph{snapshot} is JSON-encoded textual database held by quorum nodes, but unlike pages, snapshots are short-term and volatile. They are used for propagating very new records and receiving records from other quorum nodes, and are only held and processed by quorum nodes in the current day. Snapshots contain three fields: \emph{originTime}, \emph{recentRecords}, and \emph{snapshotSig}.

\begin{description}
	\item[originTime] \hfill \\
		Unix time when the snapshot was first created.
	\item[recentRecords] \hfill \\
		A list of DNS records.
	\item[snapshotSig] \hfill \\
		The digital signature of \emph{originTime} and \emph{recentRecords}.
\end{description}

When a hidden service operator informs a quorum node about a new record, the quorum node first confirms that the record is valid (described below) and if it is, it adds that record into \emph{recentRecords} and updates \emph{snapshotSig}. 

%todo: do I describe how records are validated?

Where $ snap_{x} $ is the current snapshot at propagation iteration $ x $, at each 15 minute mark each active quorum node $ q_{j} $ performs the following:

\begin{enumerate}
	\item Generates a new snapshot, labelled $ snap_{x+1} $, sets \emph{originTime} to the current time, creates \emph{snapshotSig}, and sets $ snap_{x+1} $ to be the currently active snapshot for collecting new records.
	\item With each node $ q_{k} $ in the \emph{quorum}, $ q_{j} $ sends $ snap_{x} $ to $ q_{k} $, and receives $ s_{x, k} $ in return.
	\item After all swapping is complete, $ node_{j} $
	
get sigs from other q nodes too to thwart manip	
	
%		\begin{enumerate}
%			\item 
%
%
%
%	
%	\item Randomly selects $ M / 2 $ nodes from the $ M $ quorum nodes, defining \emph{swapSet}.
%	\item With each node $ node_{k} $ in \emph{swapSet}, it swaps $ snap_{x} $ and \emph{pageSig} with node $ node_{k} $, receiving a snapshot $ s_{x, k} $ and signature $ sig_{x, k} $, and then verifies the validity of $ s_{x, k} $. For efficiency, if $ node_{k} $ in turn selects $ node_{j} $, no swap will need to take place.
%	\item After all swapping is complete, $ node_{j} $
%		\begin{enumerate}
%			\item Archives $ snap_{x} $ and each $ s_{x, k} $ and $ sig_{x, k} $ for all $ k $ in \emph{swapSet}.
%			\item Updates its copy of $ node_{k} $'s page by merging in $ s_{x-4, k} $, then confirming that $ sig_{x, k} $ verifies against the generated page. If not, it asks $ node_{k} $ for its page so that the discrepancy can be resolved.
%			\item Updates its page by merging the contents of $ snap_{x-4} $ into \emph{recordList} and regenerates \emph{pageSig}.
%			\item Deletes $ snap_{x-4} $.
%			\item Increments $ x $.
%		\end{enumerate}
\end{enumerate}


% Page identification? Is 4b right? Need to swap all known snapshots! Delete old snapshots!
%\emph{TODO: this is incomplete. Quorum nodes send and receive a set of snapshots from other quorum nodes. They pass them along. After 4 rounds of share-with-50-percent the information should have reached all quorum nodes with a high probability, so the information can be safely added into the page and the signature updated. Likewise snapshots from other quorum nodes that are 4 rounds old can be added into its page, hence everyone will be in agreement, theoretically at least. Experiments needed and planned.}

\subsection{Synchronization}

% todo: how to derive yesterday's consensus doc from today's info

Any machine Alice, including Tor nodes wishing to become a \emph{candidate} node, can perform a full synchronization against any other machine Bob that holds the whole database. Describing today as day $ x $, Alice queries Bob for the \emph{pages} from $ \textrm{day}_{x} $'s quorum, determines the \emph{quorum} for $ \textrm{day}_{x-1} $, asks one of them for their \emph{pages}, determines $ \textrm{day}_{x-2} $'s quorum, asks one of them, and so on. Synchronization takes O($ x $) time rather than O($ x * M $) time because each of the $ M $ \emph{quorum} nodes have a copy of the \emph{pages} from all other \emph{quorum} members. Once Alice has queried all the way back to $ x = 0 $, Alice can generate the \emph{NameCache} data structure and keep itself qualified by publishing its hash. If Alice is selected a \emph{quorum} node, Alice then must generate its own \emph{page} with the appropriate back-reference according to the rules of the network.

\subsection{Registration Creation}

Any hidden service operator may claim any domain name that is not currently in use. As domain names cannot be purchased from a central authority, it is necessary to implement a system that introduces a cost of ownership. This performs three main purposes: 

\begin{enumerate}
	\item Thwarts potential flooding of system with domain registrations.
	\item Introduces a cost of investment that improves the availability of hidden services.
	\item Makes domain squatting more difficulty, where someone claims one or more domains on a whim for the sole purpose of denying them to others. As hidden service operators typically remain anonymous, it is difficulty for one to contact them and request relinquishing of a domain, nor is there a central authority to force relinquishing through a court order or other formal means.
\end{enumerate}

Therefore we incorporate a proof-of-work scheme that makes registration computationally intensive but is also easily verified by anyone. A domain registration consists of eight components: \emph{nameList}, \emph{contact}, \emph{timestamp}, \emph{consensusHash}, \emph{nonce}, \emph{pow}, \emph{recordSig}, and \emph{pubHSKey}. Let the variable \emph{central} consist of all fields except \emph{recordSig} and \emph{pow}. Fields that are optional are blank unless specified, and all fields are encoded in base64, except for \emph{nameList}, \emph{contact}, and \emph{timestamp}, which are encoded in standard UTF-8.

\begin{center}
    \begin{tabular}{ | l | l | p{9cm} |}
    \hline
    \textbf{Field} & \textbf{Required?} & \textbf{Description} \\ \hline
    nameList & Yes & A list of domains or subdomains that the hidden service operator wishes to claim. Names can be up to 32 characters long, and may point to either .tor or .onion TLDs, or any subdomain. Names can be linked up to 16 deep. \\ \hline
    contact & No & The fingerprint of the HS operator's PGP key, if he has one. If the fingerprint is listed, clients may query a public key server for this fingerprint, obtain the operator's PGP public key, and contact him over encrypted email. \\ \hline
	timestamp & Yes & The UNIX timestamp of when the operator created the registration and began the proof-of-work to validate it. \\ \hline
	consensusHash & Yes & The SHA-384 of the morning's consensus document at the time of registration. This a provable and irrefutable timestamp, since it can be matched against archives of the consensus document. Quorum nodes will not accept registration records that reference a consensus document more than 48 hours old. \\ \hline
	nonce & Yes & Four bytes that serve as a source of randomness for the proof-of-work, described below. \\ \hline
    pow & Yes & 16 bytes that demonstrate the result of the proof-of-work. \\ \hline
    recordSig & Yes & The digital signature of all preceding fields, signed using the hidden service's private key. \\ \hline
    pubHSKey & Yes & The public key of the hidden service. If the operator is claiming a subdomain of any depth, this key must match the \emph{pubHSKey} of the top domain name.\\ \hline
    \end{tabular}
\end{center}

A record is made valid through the completion of the proof-of-work process. The hidden service operator must find a \emph{nonce} such that the SHA-384 of \emph{central}, \emph{pow}, and \emph{recordSig} is $ \leq 2^\textrm{difficulty} $, where \emph{difficulty} specifies the order of magnitude of the work that must be done. For each \emph{nonce}, \emph{pow} and \emph{recordSig} must be regenerated, which effectively forces the computation to be performed by a machine owned by the HS operator. When the proof-of-work is complete, the valid and complete record is represented in JSON format for transmission to the \emph{quorum}.

%\emph{TODO: specify how difficulty increases to counteract Moore's Law. Also, is the pow even necessary, or can that be regenerated by anyone?}

\subsection{Record Modification}

A hidden service operator may wish to update his registration with more current information. He can generate and broadcast a modification record, which contains updates to the field. The proof-of-work cost is a fourth of registration creation.

\subsection{Ownership Transfer}

A hidden service operator may transfer one or more domains to a new owner. The transfer record contains the public key and signature of the originating owner and the public key of the new owner. Subdomains that are not explicitly moved to the new owner are invalid and can be reclaimed by the new owner if they wish. The proof-of-work cost is an eighth of domain registration.

\subsection{Domain Renewal}

Domain names expire every 64 days, so they must be renewed periodically. To renew a domain, a hidden a hidden service operator generates a renewal record, which resets the countdown on that domain. Subdomains, as they must match the ownership of the top domain, have no expiration themselves but rather will expire when the domain does. The proof-of-work cost is a fourth of a registration record.

\subsection{Registration Deletion}

If a hidden service operator wishes to relinquish ownership rights over any name, they can issue a deletion record. In the case of a domain name, this may happen if the hidden service key is compromised, the operator no longer has any use for the domain, or for other reasons. The deletion record contains the hidden service public key and corresponding digital signature, and once issued to the \emph{quorum} immediately triggers an expiration of that name. If it is a domain name, that domain and all subdomains are made available to others. Names can be deleted at any time with no computational cost.

\subsection{Broadcast}

A hidden service operator uses a Tor circuit to contact a \emph{quorum} node. For security purposes, they use the same circuit that their hidden service uses. They thus use their introduction point to give a record to a \emph{quorum} node, as illustrated in Figure ~\ref{fig:recordBroadcast}.

\begin{figure}[htbp]
	\centering
	\begin{tikzpicture}[->, node distance=2.5cm, main node/.style={circle, fill=blue!20, draw, font=\sffamily\Large\bfseries}]

			\node[main node] (1) {$ Q_{1} $};
			\node[main node] (2) [right of=1] {$ Q_{2} $};
			\node[main node] (3) [right of=2] {};
			\node[main node] (4) [right of=3] {$ Q_{3} $};

			\node[main node] (5) [below of=1] {};
			\node[main node] (6) [right of=5] {$ Q_{5} $};
			\node[main node] (7) [right of=6] {};
			\node[main node] (8) [right of=7] {};
		  
			\node[main node, font=\small] (9) [below of=5] {$ N_{middle} $};
			\node[main node] (10) [right of=9] {};
			\node[main node, font=\small] (11) [right of=10] {$ N_{ip} $};
			\node[main node] (12) [right of=11] {$ Q_{4} $};

			\node[main node] (13) [below of=9] {};
			\node[main node] (14) [right of=13] {};
			\node[main node, font=\small] (15) [right of=14] {$ N_{entry} $};
			\node[main node] (16) [right of=15] {HS};
			
			% draw 1st and 2nd part of circuit
			\tikzstyle{EdgeStyle}=[bend right=12, -, green]
			\Edge[](16)(15)
			\Edge[](9)(15)
			
			% draw last part of circuit
			\tikzstyle{EdgeStyle}=[bend left=17, -, green]
			\Edge[](9)(11)
			
			% draw record moving from exit to 1st q. node
			\draw[thick, red, <-, postaction={decorate, decoration={text along path, text align=center, text={record}, raise=3pt}}] (6) to [bend right=15] (11){};
			
			% draw upper left propegation
			\tikzstyle{EdgeStyle}=[bend left=12, ->, blue]
			\Edge[](6)(2)
			\Edge[](6)(1)
			
			% draw upper right propegation
			\tikzstyle{EdgeStyle}=[bend left=20, ->, blue]
			\Edge[](6)(12)
			\draw[thick, blue, postaction={decorate, decoration={text along path, text align=center, text={snapshot}, raise=3pt}}] (6) to [bend right=18] (4){};

		\end{tikzpicture}
	\caption{The hidden service operator uses his existing circuit (green) to inform \emph{quorum} node $ Q_{5} $ of the new record. $ Q_{5} $ then distributes it via \emph{snapshots} to all other \emph{quorum} nodes $ Q_{1..4} $, where it is recorded in \emph{pages} for long-term storage.}
	\label{fig:recordBroadcast}
\end{figure}

\subsection{Registration Query}

When a Tor user wishes to visit example.tor, his client software must first perform a query to obtain the .onion address that corresponds to that domain name. The client must be able to verify that the received record originated from the desired hidden service, akin to SSL certificates on the Clearnet. Furthermore, the lookup must happen in an anonymous or privacy-enhanced manner and the details of the query must be handled behind-the-scenes, invisibly to the user. These policies satisfy our verifiability, privacy, and simplicity requirements.

At startup, the Tor client software may build a circuit to a quorum node or to any node mirroring the database. He then asks the node server for the domain name. Depending on the verification level specified by the client, this could be limited or large amounts of information. As we mentioned in the requirements section, it is impractical to require the client to download the entire DNS database to perform verification, so instead the client can perform various degrees of verification with minimal information.

At level 1, the server returns just returns the creation record. The client software then extracts the fields, uses \emph{pubHSKey} to confirm that \emph{recordSig} verifies the record, then confirms the proof-of-work. The client then uses \emph{pubHSKey} to generate the hidden service .onion address (eight bytes of the base32-encoded SHA-1 hash of the PKCS.1 DER encoding of \emph{pubHSKey}) and looks up the hidden service in the traditional manner. The lookup fails if the service has not published a recent hidden service desciptor to the distributed hash table, otherwise the lookup goes through. End-to-end verification is complete when \emph{pubHSKey} can be successfully used to encrypt the hidden service cookie and the service proves that it can decrypt $ sec $.

At level 2, the server return the record, the page that it was included in, the \emph{pageSig} from all quorum nodes on that day, and an archive of the consensus document. This is \emph{width verification}; the client can verify the authenticity of the consensus document, determine the old quorum members and their keys, hash the page, and then verify that all the \emph{pageSig}s verify against that hash. The client then proceeds with record verification and hidden service lookup, as specified in level 1.

At level 3, the server return the record, the page that contained that record, and the pages that form the chain below it. This is \emph{depth verification}; the client can confirm the length of the page-chain and records contained within. This is demanding both in computation and in bandwidth usage, but is an extremely thorough level of verification. 

\emph{TODO: at level 4, include consensus documents so that the old quorums can be found?}

At all levels, the server may return the introduction point for that hidden service, which the node can determine in advance by querying the distributed hash table and then cashing the result. This would significantly improve performance because the client can skip that step.


%At a high level, domain registrations are broadcasted through a Tor circuit to all committee nodes. Every node then analyses the registration as well as its knowledge of the chain and makes a decision. If the registration is invalid, the node rejects with an appropriate flag. If the domain name is already taken, the node returns a flag along with the pre-existing registration. Otherwise, it digitally signs its approval and the proposal itself and distributes this to the rest of the committee. It then waits for the rest of the committee votes. Since every Tor node has the up-to-date public keys of all other nodes due to the consensus documents, every committee member can verify the votes of all other committee members. Once the node confirms that all committee nodes received the same proposal and that a significant majority indicate that the domain is both valid and available, it adds the registration to its local storage. More importantly, the registration is recorded to an append-only endless scroll distributed within the Tor network. Thus domain names are consumed in a first-come-first-serve basis.

%The scroll is a distributed and highly redundant chained data structure that slowly rolls through the Tor network. The scroll is $ N $ by $ M $ in shape and consists of two primary components: \emph{blocks} and \emph{captures}. Blocks contain one or more captures, and blocks are duplicated across the $ M $ committee nodes. Each capture is a collection of information from one day; it contains the consensus document from the previous morning, a list of domain registrations approved that day, the approval sign-off digital signatures from the committee nodes on those registrations, the digital signatures from the committee indicating their approval of the integrity of the scroll, and the hash of the previous four captures. In this way, captures are fully verifiable and contain enough information to link to the previous capture, forming a chain. This chain is not held by any single Tor node, rather it is encapsulated within a rolling window of blocks $ N $ days deep. As the days progress, the captures in the oldest block are migrated to the current day's block, rolling the structure forward. Thus the scroll is divided across $ N $ blocks, with copies of each block held by $ M $ Tor nodes. I consider $ N = 16, M = 64 $ reasonable values, which would involve 1,024 nodes at any given time, although $ M $ can be easily changed even while the scroll is in use.

%This distributed system provides the ability to confirm a given domain name is not already in use, without relying on a single central authority. Assuming that the committee nodes are honest in their vote and trustworthy in their nature, this achieves all three properties of Zooko's Triangle. Even if the committee nodes are malicious, I believe I can introduce sufficient countermeasures to make it infeasible for an attacker to successfully manipulate the system, assuming that the majority of the Tor network is trustworthy. More research, design, and implementation is needed, but this I believe is a very promising approach.


% Each node then votes on the proposed registration. A vote consists of \emph{decision}, \emph{hash}, \emph{count}, \emph{root}, and \emph{signature} where \emph{decision} is either \emph{available}, \emph{unavailable}, or \emph{invalid}; \emph{hash} is the SHA256 of the registration it received; \emph{count} is the number of valid registrations it has in local storage; \emph{root} is the root node of the Merkle tree formed by those registrations; and \emph{signature} is the digital signature of the preceding fields.

% \emph{count} and \emph{root} will both be used to keep nodes synchronized with one another. Although I won't go into detail here, my plan calls for out-of-date nodes to attempt to synchronize with the node that advertises the highest \emph{count}. Synchronization also involves checking the votes, so falsely advertising a high \emph{count} isn't sufficient to mislead the network. \emph{root} is useful because it enables quick verification that nodes have synchronized lists and the use of a Merkle tree in general allows efficient synchronization when a node is out-of-date.

\section{Examples and Structural Induction}

\subsection{Base Case}

In the most trivial base case of a single quorum node \emph{candidate} $ c_{1} $, a hidden service Bob, and a Tor client Alice, the procedures are relatively simple. On $ \textrm{day}_{0} $, $ c_{1} $ generates an initial page $ p_{1,1} $ containing no records and signs $ p_{1,1} $, but does not accept records for this initial page. $ p_{1,1} $ appears in Figure ~\ref{fig:emptyPage}.

\begin{figure}
	\begin{lstlisting}
	{
		"prevHash": 0,
		"recordList": [],
		"consensusDocHash": "uU0nuZNNPgilLlLX2n2r+sSE7+N6U4DukIj3rOLvzek=",
		"nodeFingerprint": "2FC06226AE152FBAB7620BB107CDEF0E70876A7B",
		"pageSig": "KSaOfzrXIZclHFcYxI+3jBwLs943wxVv3npI5ccY/kBEpyXRSopzjoFs746n0tJqUpdY4Kbe6DBwERaN7ELmSSK9Pu6q8QeKzNAh+QOnKl0fKBN7fqowjkQ3ktFkR0Vuox9WrrbNTMa4+up0Np52hlbKA3zSRz4fbR9NVlh6uuQ="
	}
	\end{lstlisting}
	\caption{A sample empty \emph{page}, $ p_{1,1} $, encoded in JSON and base64.}
	\label{fig:emptyPage}
\end{figure}

On $ \textrm{day}_{1} $, $ c_{1} $ examines its database of page-chains and generates a new page, $ p_{2,1} $, that references $ p_{1,1} $, a chain with 0 references, the most in the database. The hidden service \emph{Bob} hashes the consensus document, generating \emph{T/q7q052MgJGLfH1mBGUQSF YjwVn9VvOWBoOmevPZgY=} which is then fed into the Mersenne Twister to scramble the list of \emph{candidate} nodes. Since $ c_{1} $ is the only \emph{candidate}, he is chosen a member of the \emph{quorum}. Bob then builds a circuit to $ c_{1} $, and sends him a registration record, $ r_{reg} $, which appears in Figure ~\ref{fig:sampleRecord}.

\begin{figure}
	\begin{lstlisting}
	{
		"names": {
			"example.tor": "exampleruyw6wgve.onion",
			"sub.example.tor": "example.tor"
		}
		"contact": "AD97364FC20BEC80",
		"timestamp": 1424045024,
		"consensusHash": "uU0nuZNNPgilLlLX2n2r+sSE7+N6U4DukIj3rOLvzek=",
		"nonce": "AAAABw==",
		"pow": "4I4dzaBwi4AIZW8s2m0hQQ==",
		"recordSig": 	"KSaOfzrXIZclHFcYxI+3jBwLs943wxVv3npI5ccY/kBEpyXRSopzjoFs746n0tJqUpdY4Kbe6DBwERaN7ELmSSK9Pu6q8QeKzNAh+QOnKl0fKBN7fqowjkQ3ktFkR0Vuox9WrrbNTMa4+up0Np52hlbKA3zSRz4fbR9NVlh6uuQ=",
		"pubHSKey": "MIGhMA0GCSqGSIb3DQEBAQUAA4GPADCBiwKBgQDE7CP/kgwtJhTTc4JpuPkvA7Ln9wgc+fgTKgkyUp1zusxgUAn1c1MGx4YhO42KPB7dyZOf3pcRk94XsYFY1ULkF2+tf9KdNe7GFzJyMFCQENnUcVXbcwLH4vAeiGK7R/nScbCbyc9LT+VE1fbKchTL1QzLVBLqJTxhR+9YPi8x+QIFAdZ8BJs="
	}
	\end{lstlisting}
	\caption{Sample registration record from a hidden service, encoded in JSON and base64. The ``sub.example.tor'' $ \to $ ``example.tor'' $ \to $ ``exampleruyw6wgve.onion'' references can be resolved recursively.}
	\label{fig:sampleRecord}
\end{figure}

$ c_{1} $ adds this record to its snapshot, creating Figure ~\ref{fig:sampleSnapshot}.

\begin{figure}
	\begin{lstlisting}
	{
		"originTime": 1424042032,
		"recentRecords: [
			{
				"prevHash": 0,
				"recordList": 0,
				"consensusDocHash": "uU0nuZNNPgilLlLX2n2r+sSE7+N6U4DukIj3rOLvzek=",
				"nodeFingerprint": "2FC06226AE152FBAB7620BB107CDEF0E70876A7B",
				"pageSig": 	"KSaOfzrXIZclHFcYxI+3jBwLs943wxVv3npI5ccY/kBEpyXRSopzjoFs746n0tJqUpdY4Kbe6DBwERaN7ELmSSK9Pu6q8QeKzNAh+QOnKl0fKBN7fqowjkQ3ktFkR0Vuox9WrrbNTMa4+up0Np52hlbKA3zSRz4fbR9NVlh6uuQ="
			}
		],
		"nodeFingerprint": "2FC06226AE152FBAB7620BB107CDEF0E70876A7B",
		"snapshotSig": "FUgZLuFUbh0E0AKbrl1k7/4O7ucPvlr7QFkG1i9/mNFgyH/6TwNQ+
			d2Gsch/9FaN6ZjyHAnvjmSpRRSngR0UD20FwpAZ1vCVA0qO2yDZeuBd6DiNS
			kkdSueRHOF7OD95Rb04JmAk1jXjEgFb+BH3hUH54ZEaqlJvQ8tBQJ7YtAc="
	}
	\end{lstlisting}
	\caption{Sample snapshot from $ c_{1} $, containing one registration record $ r_{reg} $ from a hidden service.}
	\label{fig:sampleSnapshot}
\end{figure}

$ c_{1} $ can continue to accept and insert records in this way, but if $ r_{reg} $ is the only one that $ c_{1} $ receives, at the next 15 minute mark $ c_{1} $ will attempt to propagate this snapshot to other \emph{quorum} nodes. However, as $ c_{1} $ is the only \emph{quorum} node, nothing need happen here. $ c_{1} $ then adds $ r_{reg} $ into its page, creating $ p_{1,1} $, shown in Figure ~\ref{fig:c1page}.

\begin{figure}
	\begin{lstlisting}
	{
		"prevHash": 0,
		"recordList": [
			{
				"names": {
				"example.tor": "exampleruyw6wgve.onion",
				"sub.example.tor": "example.tor"
			}
			"contact": "AD97364FC20BEC80",
			"timestamp": 1424045024,
			"consensusHash": "uU0nuZNNPgilLlLX2n2r+sSE7+N6U4DukIj3rOLvzek=",
			"nonce": "AAAABw==",
			"pow": "4I4dzaBwi4AIZW8s2m0hQQ==",
			"recordSig": 	"KSaOfzrXIZclHFcYxI+3jBwLs943wxVv3npI5ccY/kBEpyXRSopzjoFs746n0tJqUpdY4Kbe6DBwERaN7ELmSSK9Pu6q8QeKzNAh+QOnKl0fKBN7fqowjkQ3ktFkR0Vuox9WrrbNTMa4+up0Np52hlbKA3zSRz4fbR9NVlh6uuQ=",
			"pubHSKey": "MIGhMA0GCSqGSIb3DQEBAQUAA4GPADCBiwKBgQDE7CP/kgwtJhTTc4JpuPkvA7Ln9wgc+fgTKgkyUp1zusxgUAn1c1MGx4YhO42KPB7dyZOf3pcRk94XsYFY1ULkF2+tf9KdNe7GFzJyMFCQENnUcVXbcwLH4vAeiGK7R/nScbCbyc9LT+VE1fbKchTL1QzLVBLqJTxhR+9YPi8x+QIFAdZ8BJs="
			}
		],
		"consensusDocHash": "T/q7q052MgJGLfH1mBGUQSFYjwVn9VvOWBoOmevPZgY=",
		"nodeFingerprint": "2FC06226AE152FBAB7620BB107CDEF0E70876A7B",
		"pageSig": "KO7FXtoTJmxceJYlW202c0WwRGRyU9m99IskcL9yv/wFQ4ubzbjVs8LQzwQub9kDJ8Htpc9rRZvneRRbusFv1nvaeJw+WgRt+Tck0uapndHKYaQcK3XTIFYdmT1lLm7QxSKjnIxgBkwKT0QWdGLUhuRgGe5CXmqrPeDfU/gsgLs="
	}
	\end{lstlisting}
	\caption{$ c_{1} $'s page, containing a single registration record.}
	\label{fig:c1page}
\end{figure}

This record $ \to $ snapshot $ \to $ page merge process continues for any new records, but assuming $ r_{reg} $ is the only record received that day, $ p_{1,1} $ will not change following the end of $ \textrm{day}_{1} $. On $ \textrm{day}_{2} $, $ c_{1} $, again a $ quorum $ member, will build a page $ p_{1,2} $ that links to $ p_{1,1} $, the latest page in the chain with the most links, now 2. Generally speaking, on day $ \textrm{day}_{n} $ $ c_{1} $ will select $ p_{1,n-1} $, as there is no other choice. It alone listens for new records, rejects new registrations if there is a name conflict, and ensure the validity of the entire page-chain database. The Tor client Alice, wishing to contact the hidden service Bob, may query $ c_{1} $ for ``example.tor'' and $ c_{1} $ returns $ r_{reg} $. Alice can then confirm the validity of $ r_{reg} $ herself, follow ``example.tor'' to ``exampleruyw6wgve.onion'', and finally perform the traditional hidden service lookup.

\subsection{First Expansion}

Extending the example to two \emph{candidates} $ c_{1} $ and $ c_{2} $, a mirror $ m_{1} $, a hidden service Bob, and a Tor client Alice, the purpose of the \emph{snapshot} and \emph{NameCache} data structures become more clear. As before, on $ \textrm{day}_{0} $, $ c_{1} $ and $ c_{2} $ both generate and sign initial empty pages but do not accept records. However, on $ \textrm{day}_{1} $, $ c_{1} $ and $ c_{2} $ 

This is illustrated in Figure ~\ref{fig:bigPicture}.

generates an initial page $ p_{1,1} $ containing no records and signs $ p_{1,1} $, but does not accept records for this initial page.

\begin{figure}[htbp]
	\centering
	\begin{tikzpicture}[->, node distance=2.5cm, main node/.style={circle, fill=blue!20, draw, font=\sffamily\Large\bfseries}]

			\node[main node, font=\small] (1) {$ A_{entry} $};
			\node[main node] (2) [right of=1] {};
			\node[main node] (3) [right of=2] {Alice};
			\node[main node] (4) [right of=3] {};

			\node[main node, font=\small] (5) [below of=1] {$ A_{exit} $};
			\node[main node, font=\small] (6) [right of=5] {$ A_{middle} $};
			\node[main node] (7) [right of=6] {$ c_{1} $};
			\node[main node] (8) [right of=7] {$ c_{2} $};
		  
			\node[main node] (9) [below of=5] {};
			\node[main node] (10) [right of=9] {$ m_{1} $};
			\node[main node] (11) [right of=10] {};
			\node[main node, font=\small] (12) [right of=11] {$ B_{ip} $};

			\node[main node] (13) [below of=9] {};
			\node[main node, font=\small] (14) [right of=13] {$ B_{middle} $};
			\node[main node, font=\small] (15) [right of=14] {$ B_{entry} $};
			\node[main node] (16) [right of=15] {Bob};
		  
			%http://www.texample.net/tikz/examples/tkz-berge/
			%http://www.texample.net/tikz/examples/graph/
			
			\tikzstyle{EdgeStyle}=[bend right, -, green]
			\Edge[](3)(1)
			\tikzstyle{EdgeStyle}=[bend left=15, -, green]
			\Edge[](1)(6)
			\Edge[](5)(6)
			
			\draw[thick, <-, blue, postaction={decorate, decoration={text along path, text align=center, text={response}, raise=3pt}}] (5) to [bend right=15] (10){};
			
			\draw[thick, red, <-, postaction={decorate, decoration={text along path, text align=center, text={sync}, raise=3pt}}] (10) to [bend right=15] (7){};
			
			\tikzstyle{EdgeStyle}=[bend right=15, -, green]
			\Edge[](16)(15)
			\Edge[](15)(14)
			\tikzstyle{EdgeStyle}=[bend left=10, -, green]
			\Edge[](14)(12)
			\draw[thick, blue, postaction={decorate, decoration={text along path, text align=center, text={record}, raise=3pt}}] (12) to [bend left=15] (8){};
			
			\tikzstyle{EdgeStyle}=[-, gray]
			\Edge[](7)(8)
			
			
			%\draw[edge] (16) -- (15) -- (14) -- (12);
%			
%			\tikzstyle{edge day2} = [draw, thick, -, black, dotted]
%			\draw[edge day2] (11) -- (7) -- (4);
%			
%			\tikzstyle{edge day3} = [draw, thick, -, black]
%			\draw[edge day3] (5) -- (10) -- (16);

		\end{tikzpicture}
	\caption{The hidden service operator Bob anonymously sends a record to the \emph{quorum} ($ c_{1} $ and $ c_{2} $), informing them about his domain name. A node $ m_{1} $ mirrors the \emph{quorum}, which Alice anonymously queries for Bob's domain name.}
	\label{fig:bigPicture}
\end{figure}

\subsection{General Example}

Generally, with $ N \in \textbf{Z} $ \emph{candidate} nodes, a \emph{quorum} of size $ M \in \textbf{Z} $, $ H \in \textbf{Z} $ hidden services, and $ C \in \textbf{Z} $ clients,

\section{Fault Tolerance}

Tor nodes have no reliability guarantee and may disappear from the network momentarily or permanently at any time. 



